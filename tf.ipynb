{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:02,419] Making new env: CartPole-v0\n",
      "[2017-05-31 06:59:02,468] Clearing 24 monitor files from previous run (because force=True was provided)\n",
      "[2017-05-31 06:59:02,474] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000000.mp4\n",
      "[2017-05-31 06:59:04,937] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 48 timesteps\n",
      "0 48.0 48.0\n",
      "Episode finished after 16 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:05,158] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 16.0 48.0\n",
      "Episode finished after 10 timesteps\n",
      "2 10.0 48.0\n",
      "Episode finished after 36 timesteps\n",
      "3 36.0 48.0\n",
      "Episode finished after 15 timesteps\n",
      "4 15.0 48.0\n",
      "Episode finished after 19 timesteps\n",
      "5 19.0 48.0\n",
      "Episode finished after 26 timesteps\n",
      "6 26.0 48.0\n",
      "Episode finished after 26 timesteps\n",
      "7 26.0 48.0\n",
      "Episode finished after 19 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:05,918] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000027.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 19.0 48.0\n",
      "Episode finished after 21 timesteps\n",
      "9 21.0 48.0\n",
      "Episode finished after 24 timesteps\n",
      "10 24.0 48.0\n",
      "Episode finished after 26 timesteps\n",
      "11 26.0 48.0\n",
      "Episode finished after 13 timesteps\n",
      "12 13.0 48.0\n",
      "Episode finished after 30 timesteps\n",
      "13 30.0 48.0\n",
      "Episode finished after 14 timesteps\n",
      "14 14.0 48.0\n",
      "Episode finished after 19 timesteps\n",
      "15 19.0 48.0\n",
      "Episode finished after 32 timesteps\n",
      "16 32.0 48.0\n",
      "Episode finished after 13 timesteps\n",
      "17 13.0 48.0\n",
      "Episode finished after 43 timesteps\n",
      "18 43.0 48.0\n",
      "Episode finished after 13 timesteps\n",
      "19 13.0 48.0\n",
      "Episode finished after 41 timesteps\n",
      "20 41.0 48.0\n",
      "Episode finished after 17 timesteps\n",
      "21 17.0 48.0\n",
      "Episode finished after 31 timesteps\n",
      "22 31.0 48.0\n",
      "Episode finished after 15 timesteps\n",
      "23 15.0 48.0\n",
      "Episode finished after 9 timesteps\n",
      "24 9.0 48.0\n",
      "Episode finished after 32 timesteps\n",
      "25 32.0 48.0\n",
      "Episode finished after 14 timesteps\n",
      "26 14.0 48.0\n",
      "Episode finished after 32 timesteps\n",
      "27 32.0 48.0\n",
      "Episode finished after 25 timesteps\n",
      "28 25.0 48.0\n",
      "Episode finished after 18 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:06,762] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000064.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 18.0 48.0\n",
      "Episode finished after 38 timesteps\n",
      "30 38.0 48.0\n",
      "Episode finished after 17 timesteps\n",
      "31 17.0 48.0\n",
      "Episode finished after 26 timesteps\n",
      "32 26.0 48.0\n",
      "Episode finished after 13 timesteps\n",
      "33 13.0 48.0\n",
      "Episode finished after 25 timesteps\n",
      "34 25.0 48.0\n",
      "Episode finished after 31 timesteps\n",
      "35 31.0 48.0\n",
      "Episode finished after 40 timesteps\n",
      "36 40.0 48.0\n",
      "Episode finished after 13 timesteps\n",
      "37 13.0 48.0\n",
      "Episode finished after 28 timesteps\n",
      "38 28.0 48.0\n",
      "Episode finished after 14 timesteps\n",
      "39 14.0 48.0\n",
      "Episode finished after 12 timesteps\n",
      "40 12.0 48.0\n",
      "Episode finished after 64 timesteps\n",
      "41 64.0 64.0\n",
      "Episode finished after 11 timesteps\n",
      "42 11.0 64.0\n",
      "Episode finished after 26 timesteps\n",
      "43 26.0 64.0\n",
      "Episode finished after 36 timesteps\n",
      "44 36.0 64.0\n",
      "Episode finished after 10 timesteps\n",
      "45 10.0 64.0\n",
      "Episode finished after 15 timesteps\n",
      "46 15.0 64.0\n",
      "Episode finished after 17 timesteps\n",
      "47 17.0 64.0\n",
      "Episode finished after 20 timesteps\n",
      "48 20.0 64.0\n",
      "Episode finished after 22 timesteps\n",
      "49 22.0 64.0\n",
      "Episode finished after 18 timesteps\n",
      "50 18.0 64.0\n",
      "Episode finished after 15 timesteps\n",
      "51 15.0 64.0\n",
      "Episode finished after 18 timesteps\n",
      "52 18.0 64.0\n",
      "Episode finished after 24 timesteps\n",
      "53 24.0 64.0\n",
      "Episode finished after 12 timesteps\n",
      "54 12.0 64.0\n",
      "Episode finished after 32 timesteps\n",
      "55 32.0 64.0\n",
      "Episode finished after 14 timesteps\n",
      "56 14.0 64.0\n",
      "Episode finished after 29 timesteps\n",
      "57 29.0 64.0\n",
      "Episode finished after 15 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:08,616] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000125.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 15.0 64.0\n",
      "Episode finished after 12 timesteps\n",
      "59 12.0 64.0\n",
      "Episode finished after 21 timesteps\n",
      "60 21.0 64.0\n",
      "Episode finished after 21 timesteps\n",
      "61 21.0 64.0\n",
      "Episode finished after 64 timesteps\n",
      "62 64.0 64.0\n",
      "Episode finished after 11 timesteps\n",
      "63 11.0 64.0\n",
      "Episode finished after 19 timesteps\n",
      "64 19.0 64.0\n",
      "Episode finished after 19 timesteps\n",
      "65 19.0 64.0\n",
      "Episode finished after 18 timesteps\n",
      "66 18.0 64.0\n",
      "Episode finished after 12 timesteps\n",
      "67 12.0 64.0\n",
      "Episode finished after 12 timesteps\n",
      "68 12.0 64.0\n",
      "Episode finished after 72 timesteps\n",
      "69 72.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "70 14.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "71 11.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "72 26.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "73 12.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "74 12.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "75 13.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "76 26.0 72.0\n",
      "Episode finished after 38 timesteps\n",
      "77 38.0 72.0\n",
      "Episode finished after 46 timesteps\n",
      "78 46.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "79 14.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "80 31.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "81 13.0 72.0\n",
      "Episode finished after 53 timesteps\n",
      "82 53.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "83 14.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "84 32.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "85 22.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "86 26.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "87 20.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "88 16.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "89 26.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "90 17.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "91 37.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "92 14.0 72.0\n",
      "Episode finished after 41 timesteps\n",
      "93 41.0 72.0\n",
      "Episode finished after 50 timesteps\n",
      "94 50.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "95 14.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "96 17.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "97 18.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "98 25.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "99 13.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "100 25.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "101 23.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "102 16.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "103 24.0 72.0\n",
      "Episode finished after 18 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:10,482] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000216.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104 18.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "105 18.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "106 29.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "107 13.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "108 27.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "109 10.0 72.0\n",
      "Episode finished after 41 timesteps\n",
      "110 41.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "111 12.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "112 24.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "113 11.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "114 14.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "115 14.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "116 16.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "117 28.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "118 16.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "119 23.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "120 12.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "121 13.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "122 26.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "123 15.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "124 25.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "125 26.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "126 23.0 72.0\n",
      "Episode finished after 39 timesteps\n",
      "127 39.0 72.0\n",
      "Episode finished after 49 timesteps\n",
      "128 49.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "129 27.0 72.0\n",
      "Episode finished after 8 timesteps\n",
      "130 8.0 72.0\n",
      "Episode finished after 45 timesteps\n",
      "131 45.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "132 12.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "133 16.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "134 21.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "135 15.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "136 12.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "137 12.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "138 16.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "139 13.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "140 17.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "141 16.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "142 27.0 72.0\n",
      "Episode finished after 53 timesteps\n",
      "143 53.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "144 11.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "145 20.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "146 25.0 72.0\n",
      "Episode finished after 53 timesteps\n",
      "147 53.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "148 15.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "149 26.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "150 29.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "151 13.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "152 12.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "153 27.0 72.0\n",
      "Episode finished after 38 timesteps\n",
      "154 38.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "155 15.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "156 29.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "157 17.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "158 16.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "159 19.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "160 13.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "161 11.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "162 35.0 72.0\n",
      "Episode finished after 42 timesteps\n",
      "163 42.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "164 17.0 72.0\n",
      "Episode finished after 42 timesteps\n",
      "165 42.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "166 21.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "167 14.0 72.0\n",
      "Episode finished after 28 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:13,606] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000343.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "168 28.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "169 18.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "170 14.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "171 29.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "172 24.0 72.0\n",
      "Episode finished after 53 timesteps\n",
      "173 53.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "174 23.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "175 23.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "176 16.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "177 18.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "178 18.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "179 35.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "180 33.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "181 25.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "182 12.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "183 29.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "184 12.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "185 34.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "186 18.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "187 12.0 72.0\n",
      "Episode finished after 45 timesteps\n",
      "188 45.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "189 14.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "190 14.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "191 25.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "192 18.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "193 11.0 72.0\n",
      "Episode finished after 44 timesteps\n",
      "194 44.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "195 17.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "196 21.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "197 35.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "198 15.0 72.0\n",
      "Episode finished after 54 timesteps\n",
      "199 54.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "200 11.0 72.0\n",
      "Episode finished after 30 timesteps\n",
      "201 30.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "202 17.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "203 21.0 72.0\n",
      "Episode finished after 40 timesteps\n",
      "204 40.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "205 29.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "206 15.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "207 9.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "208 19.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "209 18.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "210 18.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "211 22.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "212 35.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "213 10.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "214 11.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "215 19.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "216 13.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "217 29.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "218 12.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "219 14.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "220 16.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "221 9.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "222 12.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "223 17.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "224 14.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "225 19.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "226 31.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "227 11.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "228 27.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "229 16.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "230 22.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "231 10.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "232 13.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "233 16.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "234 16.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "235 37.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "236 13.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "237 31.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "238 14.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "239 13.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "240 20.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "241 22.0 72.0\n",
      "Episode finished after 48 timesteps\n",
      "242 48.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "243 19.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "244 32.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "245 34.0 72.0\n",
      "Episode finished after 38 timesteps\n",
      "246 38.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "247 23.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "248 16.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "249 18.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "250 16.0 72.0\n",
      "Episode finished after 44 timesteps\n",
      "251 44.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "252 13.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "253 22.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "254 22.0 72.0\n",
      "Episode finished after 12 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:17,032] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000512.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 12.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "256 24.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "257 11.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "258 15.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "259 13.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "260 13.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "261 19.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "262 19.0 72.0\n",
      "Episode finished after 55 timesteps\n",
      "263 55.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "264 35.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "265 21.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "266 22.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "267 14.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "268 27.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "269 18.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "270 18.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "271 13.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "272 20.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "273 22.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "274 14.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "275 21.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "276 13.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "277 12.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "278 20.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "279 32.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "280 16.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "281 12.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "282 22.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "283 19.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "284 17.0 72.0\n",
      "Episode finished after 48 timesteps\n",
      "285 48.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "286 16.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "287 20.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "288 11.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "289 13.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "290 15.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "291 12.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "292 11.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "293 31.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "294 15.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "295 18.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "296 19.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "297 14.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "298 9.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "299 18.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "300 15.0 72.0\n",
      "Episode finished after 58 timesteps\n",
      "301 58.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "302 24.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "303 13.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "304 12.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "305 20.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "306 10.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "307 11.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "308 28.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "309 13.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "310 16.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "311 21.0 72.0\n",
      "Episode finished after 40 timesteps\n",
      "312 40.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "313 14.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "314 26.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "315 13.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "316 15.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "317 27.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "318 37.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "319 12.0 72.0\n",
      "Episode finished after 45 timesteps\n",
      "320 45.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "321 10.0 72.0\n",
      "Episode finished after 45 timesteps\n",
      "322 45.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "323 13.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "324 16.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "325 14.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "326 16.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "327 11.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "328 22.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "329 13.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "330 11.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "331 25.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "332 35.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "333 16.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "334 27.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "335 14.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "336 17.0 72.0\n",
      "Episode finished after 42 timesteps\n",
      "337 42.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "338 23.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "339 17.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "340 23.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "341 29.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "342 11.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "343 19.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "344 17.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "345 18.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "346 26.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "347 35.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "348 22.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "349 20.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "350 25.0 72.0\n",
      "Episode finished after 70 timesteps\n",
      "351 70.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "352 20.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "353 14.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "354 27.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "355 17.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "356 13.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "357 14.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "358 11.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "359 13.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "360 15.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "361 11.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "362 24.0 72.0\n",
      "Episode finished after 53 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:21,840] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video000729.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 53.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "364 29.0 72.0\n",
      "Episode finished after 36 timesteps\n",
      "365 36.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "366 34.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "367 35.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "368 11.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "369 28.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "370 20.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "371 21.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "372 10.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "373 24.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "374 11.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "375 21.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "376 19.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "377 18.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "378 27.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "379 20.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "380 17.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "381 11.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "382 10.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "383 21.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "384 9.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "385 11.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "386 21.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "387 16.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "388 14.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "389 13.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "390 16.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "391 15.0 72.0\n",
      "Episode finished after 40 timesteps\n",
      "392 40.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "393 14.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "394 27.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "395 26.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "396 12.0 72.0\n",
      "Episode finished after 36 timesteps\n",
      "397 36.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "398 13.0 72.0\n",
      "Episode finished after 47 timesteps\n",
      "399 47.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "400 18.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "401 13.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "402 11.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "403 15.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "404 24.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "405 12.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "406 17.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "407 28.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "408 13.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "409 37.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "410 13.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "411 20.0 72.0\n",
      "Episode finished after 47 timesteps\n",
      "412 47.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "413 18.0 72.0\n",
      "Episode finished after 49 timesteps\n",
      "414 49.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "415 14.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "416 25.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "417 13.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "418 13.0 72.0\n",
      "Episode finished after 30 timesteps\n",
      "419 30.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "420 12.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "421 13.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "422 19.0 72.0\n",
      "Episode finished after 40 timesteps\n",
      "423 40.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "424 27.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "425 19.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "426 14.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "427 21.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "428 23.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "429 22.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "430 14.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "431 20.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "432 18.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "433 18.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "434 12.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "435 31.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "436 22.0 72.0\n",
      "Episode finished after 47 timesteps\n",
      "437 47.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "438 10.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "439 13.0 72.0\n",
      "Episode finished after 40 timesteps\n",
      "440 40.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "441 10.0 72.0\n",
      "Episode finished after 48 timesteps\n",
      "442 48.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "443 31.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "444 13.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "445 32.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "446 33.0 72.0\n",
      "Episode finished after 70 timesteps\n",
      "447 70.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "448 23.0 72.0\n",
      "Episode finished after 43 timesteps\n",
      "449 43.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "450 10.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "451 25.0 72.0\n",
      "Episode finished after 30 timesteps\n",
      "452 30.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "453 22.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "454 33.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "455 18.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "456 23.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "457 25.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "458 18.0 72.0\n",
      "Episode finished after 52 timesteps\n",
      "459 52.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "460 13.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "461 14.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "462 17.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "463 25.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "464 14.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "465 25.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "466 13.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "467 23.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "468 21.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "469 22.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "470 17.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "471 10.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "472 37.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "473 21.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "474 31.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "475 14.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "476 19.0 72.0\n",
      "Episode finished after 52 timesteps\n",
      "477 52.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "478 19.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "479 19.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "480 18.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "481 14.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "482 24.0 72.0\n",
      "Episode finished after 30 timesteps\n",
      "483 30.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "484 16.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "485 17.0 72.0\n",
      "Episode finished after 50 timesteps\n",
      "486 50.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "487 16.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "488 22.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "489 17.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "490 12.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "491 16.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "492 20.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "493 32.0 72.0\n",
      "Episode finished after 64 timesteps\n",
      "494 64.0 72.0\n",
      "Episode finished after 16 timesteps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:27,303] Starting new video recorder writing to /Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3/openaigym.video.0.67716.video001000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 16.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "496 32.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "497 18.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "498 18.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "499 25.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "500 15.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "501 37.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "502 13.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "503 10.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "504 21.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "505 14.0 72.0\n",
      "Episode finished after 58 timesteps\n",
      "506 58.0 72.0\n",
      "Episode finished after 47 timesteps\n",
      "507 47.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "508 15.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "509 14.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "510 13.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "511 11.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "512 21.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "513 20.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "514 13.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "515 13.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "516 23.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "517 13.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "518 21.0 72.0\n",
      "Episode finished after 38 timesteps\n",
      "519 38.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "520 12.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "521 37.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "522 12.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "523 9.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "524 12.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "525 15.0 72.0\n",
      "Episode finished after 42 timesteps\n",
      "526 42.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "527 31.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "528 10.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "529 20.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "530 18.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "531 15.0 72.0\n",
      "Episode finished after 36 timesteps\n",
      "532 36.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "533 16.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "534 26.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "535 23.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "536 20.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "537 13.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "538 18.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "539 14.0 72.0\n",
      "Episode finished after 44 timesteps\n",
      "540 44.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "541 27.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "542 12.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "543 19.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "544 20.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "545 37.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "546 15.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "547 18.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "548 18.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "549 15.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "550 17.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "551 14.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "552 19.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "553 22.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "554 26.0 72.0\n",
      "Episode finished after 51 timesteps\n",
      "555 51.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "556 14.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "557 10.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "558 19.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "559 19.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "560 14.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "561 19.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "562 15.0 72.0\n",
      "Episode finished after 41 timesteps\n",
      "563 41.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "564 27.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "565 18.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "566 10.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "567 37.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "568 18.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "569 20.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "570 24.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "571 21.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "572 23.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "573 13.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "574 31.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "575 10.0 72.0\n",
      "Episode finished after 67 timesteps\n",
      "576 67.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "577 21.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "578 35.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "579 29.0 72.0\n",
      "Episode finished after 53 timesteps\n",
      "580 53.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "581 22.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "582 16.0 72.0\n",
      "Episode finished after 8 timesteps\n",
      "583 8.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "584 22.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "585 37.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "586 9.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "587 25.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "588 12.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "589 21.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "590 24.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "591 17.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "592 17.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "593 17.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "594 18.0 72.0\n",
      "Episode finished after 53 timesteps\n",
      "595 53.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "596 20.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "597 28.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "598 13.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "599 11.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "600 25.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "601 10.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "602 18.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "603 13.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "604 20.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "605 28.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "606 26.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "607 11.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "608 16.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "609 17.0 72.0\n",
      "Episode finished after 8 timesteps\n",
      "610 8.0 72.0\n",
      "Episode finished after 58 timesteps\n",
      "611 58.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "612 35.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "613 24.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "614 31.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "615 24.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "616 10.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "617 14.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "618 25.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "619 23.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "620 24.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "621 15.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "622 15.0 72.0\n",
      "Episode finished after 45 timesteps\n",
      "623 45.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "624 16.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "625 16.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "626 15.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "627 28.0 72.0\n",
      "Episode finished after 43 timesteps\n",
      "628 43.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "629 29.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "630 26.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "631 20.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "632 22.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "633 17.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "634 21.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "635 15.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "636 16.0 72.0\n",
      "Episode finished after 44 timesteps\n",
      "637 44.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "638 14.0 72.0\n",
      "Episode finished after 35 timesteps\n",
      "639 35.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "640 29.0 72.0\n",
      "Episode finished after 46 timesteps\n",
      "641 46.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "642 19.0 72.0\n",
      "Episode finished after 48 timesteps\n",
      "643 48.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "644 14.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "645 15.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "646 25.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "647 12.0 72.0\n",
      "Episode finished after 40 timesteps\n",
      "648 40.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "649 16.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "650 18.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "651 20.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "652 18.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "653 32.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "654 33.0 72.0\n",
      "Episode finished after 48 timesteps\n",
      "655 48.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "656 13.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "657 21.0 72.0\n",
      "Episode finished after 40 timesteps\n",
      "658 40.0 72.0\n",
      "Episode finished after 65 timesteps\n",
      "659 65.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "660 22.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "661 33.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "662 18.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "663 19.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "664 33.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "665 16.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "666 28.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "667 12.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "668 15.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "669 13.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "670 13.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "671 34.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "672 19.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "673 15.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "674 13.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "675 18.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "676 23.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "677 20.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "678 23.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "679 10.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "680 19.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "681 11.0 72.0\n",
      "Episode finished after 41 timesteps\n",
      "682 41.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "683 14.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "684 28.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "685 16.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "686 13.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "687 14.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "688 25.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "689 28.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "690 29.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "691 25.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "692 17.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "693 29.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "694 28.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "695 12.0 72.0\n",
      "Episode finished after 62 timesteps\n",
      "696 62.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "697 12.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "698 16.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "699 14.0 72.0\n",
      "Episode finished after 49 timesteps\n",
      "700 49.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "701 12.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "702 18.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "703 17.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "704 32.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "705 12.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "706 25.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "707 23.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "708 24.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "709 28.0 72.0\n",
      "Episode finished after 41 timesteps\n",
      "710 41.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "711 13.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "712 28.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "713 12.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "714 16.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "715 32.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "716 17.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "717 13.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "718 11.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "719 27.0 72.0\n",
      "Episode finished after 37 timesteps\n",
      "720 37.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "721 17.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "722 19.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "723 22.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "724 23.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "725 14.0 72.0\n",
      "Episode finished after 47 timesteps\n",
      "726 47.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "727 22.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "728 12.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "729 20.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "730 14.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "731 31.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "732 14.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "733 14.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "734 9.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "735 15.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "736 27.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "737 25.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "738 34.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "739 12.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "740 28.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "741 15.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "742 12.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "743 22.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "744 15.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "745 18.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "746 20.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "747 31.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "748 32.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "749 12.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "750 28.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "751 15.0 72.0\n",
      "Episode finished after 43 timesteps\n",
      "752 43.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "753 16.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "754 14.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "755 11.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "756 20.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "757 22.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "758 12.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "759 29.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "760 29.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "761 14.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "762 20.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "763 26.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "764 34.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "765 14.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "766 26.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "767 10.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "768 18.0 72.0\n",
      "Episode finished after 53 timesteps\n",
      "769 53.0 72.0\n",
      "Episode finished after 65 timesteps\n",
      "770 65.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "771 13.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "772 33.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "773 15.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "774 26.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "775 20.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "776 16.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "777 18.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "778 26.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "779 21.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "780 19.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "781 20.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "782 17.0 72.0\n",
      "Episode finished after 39 timesteps\n",
      "783 39.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "784 10.0 72.0\n",
      "Episode finished after 49 timesteps\n",
      "785 49.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "786 29.0 72.0\n",
      "Episode finished after 29 timesteps\n",
      "787 29.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "788 18.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "789 16.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "790 27.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "791 11.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "792 13.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "793 22.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "794 25.0 72.0\n",
      "Episode finished after 56 timesteps\n",
      "795 56.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "796 13.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "797 17.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "798 19.0 72.0\n",
      "Episode finished after 23 timesteps\n",
      "799 23.0 72.0\n",
      "Episode finished after 38 timesteps\n",
      "800 38.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "801 15.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "802 33.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "803 17.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "804 19.0 72.0\n",
      "Episode finished after 30 timesteps\n",
      "805 30.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "806 16.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "807 14.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "808 19.0 72.0\n",
      "Episode finished after 41 timesteps\n",
      "809 41.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "810 11.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "811 10.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "812 22.0 72.0\n",
      "Episode finished after 11 timesteps\n",
      "813 11.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "814 32.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "815 16.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "816 14.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "817 32.0 72.0\n",
      "Episode finished after 49 timesteps\n",
      "818 49.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "819 16.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "820 24.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "821 20.0 72.0\n",
      "Episode finished after 36 timesteps\n",
      "822 36.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "823 13.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "824 34.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "825 28.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "826 19.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "827 25.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "828 27.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "829 22.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "830 18.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "831 25.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "832 14.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "833 26.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "834 21.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "835 13.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "836 9.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "837 33.0 72.0\n",
      "Episode finished after 21 timesteps\n",
      "838 21.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "839 16.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "840 14.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "841 20.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "842 13.0 72.0\n",
      "Episode finished after 60 timesteps\n",
      "843 60.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "844 16.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "845 17.0 72.0\n",
      "Episode finished after 13 timesteps\n",
      "846 13.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "847 18.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "848 25.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "849 14.0 72.0\n",
      "Episode finished after 28 timesteps\n",
      "850 28.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "851 32.0 72.0\n",
      "Episode finished after 9 timesteps\n",
      "852 9.0 72.0\n",
      "Episode finished after 25 timesteps\n",
      "853 25.0 72.0\n",
      "Episode finished after 39 timesteps\n",
      "854 39.0 72.0\n",
      "Episode finished after 30 timesteps\n",
      "855 30.0 72.0\n",
      "Episode finished after 34 timesteps\n",
      "856 34.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "857 16.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "858 22.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "859 19.0 72.0\n",
      "Episode finished after 10 timesteps\n",
      "860 10.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "861 20.0 72.0\n",
      "Episode finished after 31 timesteps\n",
      "862 31.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "863 26.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "864 16.0 72.0\n",
      "Episode finished after 46 timesteps\n",
      "865 46.0 72.0\n",
      "Episode finished after 45 timesteps\n",
      "866 45.0 72.0\n",
      "Episode finished after 16 timesteps\n",
      "867 16.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "868 12.0 72.0\n",
      "Episode finished after 33 timesteps\n",
      "869 33.0 72.0\n",
      "Episode finished after 32 timesteps\n",
      "870 32.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "871 22.0 72.0\n",
      "Episode finished after 19 timesteps\n",
      "872 19.0 72.0\n",
      "Episode finished after 18 timesteps\n",
      "873 18.0 72.0\n",
      "Episode finished after 26 timesteps\n",
      "874 26.0 72.0\n",
      "Episode finished after 15 timesteps\n",
      "875 15.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "876 22.0 72.0\n",
      "Episode finished after 24 timesteps\n",
      "877 24.0 72.0\n",
      "Episode finished after 22 timesteps\n",
      "878 22.0 72.0\n",
      "Episode finished after 12 timesteps\n",
      "879 12.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "880 17.0 72.0\n",
      "Episode finished after 14 timesteps\n",
      "881 14.0 72.0\n",
      "Episode finished after 17 timesteps\n",
      "882 17.0 72.0\n",
      "Episode finished after 51 timesteps\n",
      "883 51.0 72.0\n",
      "Episode finished after 20 timesteps\n",
      "884 20.0 72.0\n",
      "Episode finished after 27 timesteps\n",
      "885 27.0 72.0\n",
      "Episode finished after 79 timesteps\n",
      "886 79.0 79.0\n",
      "Episode finished after 10 timesteps\n",
      "887 10.0 79.0\n",
      "Episode finished after 29 timesteps\n",
      "888 29.0 79.0\n",
      "Episode finished after 21 timesteps\n",
      "889 21.0 79.0\n",
      "Episode finished after 18 timesteps\n",
      "890 18.0 79.0\n",
      "Episode finished after 21 timesteps\n",
      "891 21.0 79.0\n",
      "Episode finished after 19 timesteps\n",
      "892 19.0 79.0\n",
      "Episode finished after 26 timesteps\n",
      "893 26.0 79.0\n",
      "Episode finished after 19 timesteps\n",
      "894 19.0 79.0\n",
      "Episode finished after 72 timesteps\n",
      "895 72.0 79.0\n",
      "Episode finished after 83 timesteps\n",
      "896 83.0 83.0\n",
      "Episode finished after 26 timesteps\n",
      "897 26.0 83.0\n",
      "Episode finished after 10 timesteps\n",
      "898 10.0 83.0\n",
      "Episode finished after 77 timesteps\n",
      "899 77.0 83.0\n",
      "Episode finished after 48 timesteps\n",
      "900 48.0 83.0\n",
      "Episode finished after 60 timesteps\n",
      "901 60.0 83.0\n",
      "Episode finished after 15 timesteps\n",
      "902 15.0 83.0\n",
      "Episode finished after 15 timesteps\n",
      "903 15.0 83.0\n",
      "Episode finished after 29 timesteps\n",
      "904 29.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "905 11.0 83.0\n",
      "Episode finished after 27 timesteps\n",
      "906 27.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "907 13.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "908 13.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "909 13.0 83.0\n",
      "Episode finished after 42 timesteps\n",
      "910 42.0 83.0\n",
      "Episode finished after 46 timesteps\n",
      "911 46.0 83.0\n",
      "Episode finished after 32 timesteps\n",
      "912 32.0 83.0\n",
      "Episode finished after 22 timesteps\n",
      "913 22.0 83.0\n",
      "Episode finished after 10 timesteps\n",
      "914 10.0 83.0\n",
      "Episode finished after 22 timesteps\n",
      "915 22.0 83.0\n",
      "Episode finished after 12 timesteps\n",
      "916 12.0 83.0\n",
      "Episode finished after 19 timesteps\n",
      "917 19.0 83.0\n",
      "Episode finished after 20 timesteps\n",
      "918 20.0 83.0\n",
      "Episode finished after 18 timesteps\n",
      "919 18.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "920 13.0 83.0\n",
      "Episode finished after 14 timesteps\n",
      "921 14.0 83.0\n",
      "Episode finished after 20 timesteps\n",
      "922 20.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "923 13.0 83.0\n",
      "Episode finished after 19 timesteps\n",
      "924 19.0 83.0\n",
      "Episode finished after 9 timesteps\n",
      "925 9.0 83.0\n",
      "Episode finished after 10 timesteps\n",
      "926 10.0 83.0\n",
      "Episode finished after 28 timesteps\n",
      "927 28.0 83.0\n",
      "Episode finished after 21 timesteps\n",
      "928 21.0 83.0\n",
      "Episode finished after 12 timesteps\n",
      "929 12.0 83.0\n",
      "Episode finished after 14 timesteps\n",
      "930 14.0 83.0\n",
      "Episode finished after 20 timesteps\n",
      "931 20.0 83.0\n",
      "Episode finished after 23 timesteps\n",
      "932 23.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "933 11.0 83.0\n",
      "Episode finished after 27 timesteps\n",
      "934 27.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "935 11.0 83.0\n",
      "Episode finished after 25 timesteps\n",
      "936 25.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "937 11.0 83.0\n",
      "Episode finished after 21 timesteps\n",
      "938 21.0 83.0\n",
      "Episode finished after 8 timesteps\n",
      "939 8.0 83.0\n",
      "Episode finished after 39 timesteps\n",
      "940 39.0 83.0\n",
      "Episode finished after 30 timesteps\n",
      "941 30.0 83.0\n",
      "Episode finished after 16 timesteps\n",
      "942 16.0 83.0\n",
      "Episode finished after 19 timesteps\n",
      "943 19.0 83.0\n",
      "Episode finished after 18 timesteps\n",
      "944 18.0 83.0\n",
      "Episode finished after 21 timesteps\n",
      "945 21.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "946 13.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "947 11.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "948 13.0 83.0\n",
      "Episode finished after 14 timesteps\n",
      "949 14.0 83.0\n",
      "Episode finished after 26 timesteps\n",
      "950 26.0 83.0\n",
      "Episode finished after 24 timesteps\n",
      "951 24.0 83.0\n",
      "Episode finished after 28 timesteps\n",
      "952 28.0 83.0\n",
      "Episode finished after 44 timesteps\n",
      "953 44.0 83.0\n",
      "Episode finished after 36 timesteps\n",
      "954 36.0 83.0\n",
      "Episode finished after 17 timesteps\n",
      "955 17.0 83.0\n",
      "Episode finished after 21 timesteps\n",
      "956 21.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "957 11.0 83.0\n",
      "Episode finished after 22 timesteps\n",
      "958 22.0 83.0\n",
      "Episode finished after 18 timesteps\n",
      "959 18.0 83.0\n",
      "Episode finished after 21 timesteps\n",
      "960 21.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "961 13.0 83.0\n",
      "Episode finished after 52 timesteps\n",
      "962 52.0 83.0\n",
      "Episode finished after 15 timesteps\n",
      "963 15.0 83.0\n",
      "Episode finished after 37 timesteps\n",
      "964 37.0 83.0\n",
      "Episode finished after 17 timesteps\n",
      "965 17.0 83.0\n",
      "Episode finished after 18 timesteps\n",
      "966 18.0 83.0\n",
      "Episode finished after 12 timesteps\n",
      "967 12.0 83.0\n",
      "Episode finished after 16 timesteps\n",
      "968 16.0 83.0\n",
      "Episode finished after 48 timesteps\n",
      "969 48.0 83.0\n",
      "Episode finished after 23 timesteps\n",
      "970 23.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "971 11.0 83.0\n",
      "Episode finished after 18 timesteps\n",
      "972 18.0 83.0\n",
      "Episode finished after 9 timesteps\n",
      "973 9.0 83.0\n",
      "Episode finished after 14 timesteps\n",
      "974 14.0 83.0\n",
      "Episode finished after 15 timesteps\n",
      "975 15.0 83.0\n",
      "Episode finished after 19 timesteps\n",
      "976 19.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "977 11.0 83.0\n",
      "Episode finished after 29 timesteps\n",
      "978 29.0 83.0\n",
      "Episode finished after 11 timesteps\n",
      "979 11.0 83.0\n",
      "Episode finished after 44 timesteps\n",
      "980 44.0 83.0\n",
      "Episode finished after 37 timesteps\n",
      "981 37.0 83.0\n",
      "Episode finished after 16 timesteps\n",
      "982 16.0 83.0\n",
      "Episode finished after 16 timesteps\n",
      "983 16.0 83.0\n",
      "Episode finished after 33 timesteps\n",
      "984 33.0 83.0\n",
      "Episode finished after 18 timesteps\n",
      "985 18.0 83.0\n",
      "Episode finished after 12 timesteps\n",
      "986 12.0 83.0\n",
      "Episode finished after 12 timesteps\n",
      "987 12.0 83.0\n",
      "Episode finished after 15 timesteps\n",
      "988 15.0 83.0\n",
      "Episode finished after 16 timesteps\n",
      "989 16.0 83.0\n",
      "Episode finished after 23 timesteps\n",
      "990 23.0 83.0\n",
      "Episode finished after 15 timesteps\n",
      "991 15.0 83.0\n",
      "Episode finished after 20 timesteps\n",
      "992 20.0 83.0\n",
      "Episode finished after 21 timesteps\n",
      "993 21.0 83.0\n",
      "Episode finished after 14 timesteps\n",
      "994 14.0 83.0\n",
      "Episode finished after 18 timesteps\n",
      "995 18.0 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:47,607] Finished writing results. You can upload them to the scoreboard via gym.upload('/Users/nanaki/Documents/desk/code/AI_gym/CarPole/private/tmp/cartpole-experiment-3')\n",
      "[2017-05-31 06:59:47,617] [CartPole-v0] Uploading 1000 episodes of training data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 81 timesteps\n",
      "996 81.0 83.0\n",
      "Episode finished after 13 timesteps\n",
      "997 13.0 83.0\n",
      "Episode finished after 25 timesteps\n",
      "998 25.0 83.0\n",
      "Episode finished after 29 timesteps\n",
      "999 29.0 83.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-05-31 06:59:51,509] [CartPole-v0] Uploading videos of 11 training episodes (20626 bytes)\n",
      "[2017-05-31 06:59:53,055] [CartPole-v0] Creating evaluation object from ./private/tmp/cartpole-experiment-3 with learning curve and training video\n",
      "[2017-05-31 06:59:53,668] \n",
      "****************************************************\n",
      "You successfully uploaded your evaluation on CartPole-v0 to\n",
      "OpenAI Gym! You can find it at:\n",
      "\n",
      "    https://gym.openai.com/evaluations/eval_HnX9rsnfQUSLo49IW4K0Pg\n",
      "\n",
      "****************************************************\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import gym\n",
    "from gym import wrappers\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "# \n",
    "STATE_NUM = 4\n",
    "\n",
    "\n",
    "class DQNAgent():\n",
    "    \"\"\"\n",
    "    Multi Layer Perceptron with Experience Replay\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, epsilon=0.99):\n",
    "        # parameters\n",
    "        # self.name = os.path.splitext(os.path.basename(__file__))[0]\n",
    "        # self.environment_name = environment_name\n",
    "        self.enable_actions = [0,1] \n",
    "        self.n_actions = len(self.enable_actions)\n",
    "        self.minibatch_size = 32\n",
    "        self.replay_memory_size = 300*100\n",
    "        self.learning_rate = 0.001\n",
    "        self.discount_factor = 0.9\n",
    "        self.exploration = 0.1\n",
    "        self.epsilon = epsilon\n",
    "        self.experienceMemory=[] # \n",
    "        self.experienceMemory_local=[] # \n",
    "        self.memSize = 300*100  # (300x100)\n",
    "        self.experienceMemory_local=[] # \n",
    "        self.memPos = 0 #\n",
    "        self.batch_num = 32 # \n",
    "        self.gamma = 0.9       # \n",
    "        self.loss=0\n",
    "        self.total_reward_award=np.ones(100)*-1000 #100\n",
    "        \n",
    "\n",
    "\n",
    "        # replay memory\n",
    "        self.D = deque(maxlen=self.replay_memory_size)\n",
    "\n",
    "        # model\n",
    "        self.init_model()\n",
    "\n",
    "        # variables\n",
    "        self.current_loss = 0.0\n",
    "\n",
    "    def init_model(self):\n",
    "\n",
    "        # input layer (1 x 4)\n",
    "        self.x = tf.placeholder(tf.float32, [4])\n",
    "\n",
    "        # flatten (64)\n",
    "        x_flat = tf.reshape(self.x, [-1, 4])\n",
    "\n",
    "        # fully connected layer (32)\n",
    "        W_fc1 = tf.Variable(tf.truncated_normal([4 ,16], stddev=0.01))\n",
    "        b_fc1 = tf.Variable(tf.zeros([16]))\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(x_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        # output layer (n_actions)\n",
    "        W_out = tf.Variable(tf.truncated_normal([16, self.n_actions], stddev=0.01))\n",
    "        b_out = tf.Variable(tf.zeros([self.n_actions]))\n",
    "        self.y = tf.matmul(h_fc1, W_out) + b_out\n",
    "\n",
    "        # loss function\n",
    "        self.y_ = tf.placeholder(tf.float32, [self.n_actions])\n",
    "        self.loss = tf.reduce_mean(tf.square(self.y_ - self.y))\n",
    "\n",
    "        # train operation\n",
    "        optimizer = tf.train.RMSPropOptimizer(self.learning_rate)\n",
    "        self.training = optimizer.minimize(self.loss)\n",
    "\n",
    "        # saver\n",
    "        self.saver = tf.train.Saver()\n",
    "\n",
    "        # session\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    def get_action_value(self, state):\n",
    "        #Q_values(self, state): #\n",
    "        # Q(state, action) of all actions\n",
    "        return self.sess.run(self.y, feed_dict={self.x: state})[0]\n",
    "\n",
    "    def reduce_epsilon(self):\n",
    "        self.epsilon-=1.0/100000\n",
    "\n",
    "    def get_epsilon(self):\n",
    "        return self.epsilon\n",
    "\n",
    "    def get_action(self, state, train):\n",
    "        if train==True and np.random.rand() < self.epsilon:\n",
    "            # random\n",
    "            return np.random.choice(self.enable_actions)\n",
    "        else:\n",
    "            # max_action Q(state, action)\n",
    "            return self.enable_actions[np.argmax(self.get_action_value(state))]\n",
    "\n",
    "    def experience_local(self,old_seq, action, reward, new_seq):\n",
    "        #\n",
    "        self.experienceMemory_local.append( np.hstack([old_seq,action,reward,new_seq]) )\n",
    " \n",
    "    def store_experience(self, state, action, reward, state_1, train):\n",
    "        self.D.append((state, action, reward, state_1, train))\n",
    "\n",
    "\n",
    "    def experience_global(self,total_reward):\n",
    "        #\n",
    "        #100\n",
    "        if np.min(self.total_reward_award)<total_reward:\n",
    "            i=np.argmin(self.total_reward_award)\n",
    "            self.total_reward_award[i]=total_reward\n",
    "\n",
    "            # GOOD EXPERIENCE REPLAY\n",
    "            for x in self.experienceMemory_local:\n",
    "                self.experience( x )\n",
    "\n",
    "        #\n",
    "        if np.random.random()<0.01:\n",
    "            # # NORMAL EXPERIENCE REPLAY\n",
    "            for x in self.experienceMemory_local:\n",
    "                self.experience( x )\n",
    "\n",
    "        self.experienceMemory_local=[]\n",
    "\n",
    "    def experience(self,x):\n",
    "        if len(self.experienceMemory)>self.memSize:\n",
    "            self.experienceMemory[int(self.memPos%self.memSize)]=x\n",
    "            self.memPos+=1\n",
    "        else:\n",
    "            self.experienceMemory.append( x )\n",
    "        \n",
    "    def experience_replay(self):\n",
    "        state_minibatch = []\n",
    "        y_minibatch = []\n",
    "\n",
    "        # sample random minibatch\n",
    "        minibatch_size = min(len(self.D), self.minibatch_size)\n",
    "        minibatch_indexes = np.random.randint(0, len(self.D), minibatch_size)\n",
    "\n",
    "        for j in minibatch_indexes:\n",
    "            state_j, action_j, reward_j, state_j_1, terminal = self.D[j]\n",
    "            action_j_index = self.enable_actions.index(action_j)\n",
    "            state_j\n",
    "            y_j = self.get_action_value(state_j)\n",
    "\n",
    "            if terminal:\n",
    "                y_j[action_j_index] = reward_j\n",
    "            else:\n",
    "                # reward_j + gamma * max_action' Q(state', action')\n",
    "                y_j[action_j_index] = reward_j + self.discount_factor * np.max(self.get_action_value(state_j_1))  # NOQA\n",
    "\n",
    "            state_minibatch.append(state_j)\n",
    "            y_minibatch.append(y_j)\n",
    "\n",
    "        # training\n",
    "        self.sess.run(self.training, feed_dict={self.x: state_minibatch, self.y_: y_minibatch})\n",
    "\n",
    "        # for log\n",
    "        self.current_loss = self.sess.run(self.loss, feed_dict={self.x: state_minibatch, self.y_: y_minibatch})\n",
    "    \n",
    "    \n",
    "    def update_model(self,old_seq, action, reward, new_seq):\n",
    "        '''\n",
    "        \n",
    "        '''\n",
    "        # \n",
    "        if len(self.experienceMemory)<self.batch_num:\n",
    "            return\n",
    "\n",
    "        # \n",
    "        memsize=len(self.experienceMemory)\n",
    "        batch_index = list(np.random.randint(0,memsize,(self.batch_num)))\n",
    "        batch =np.array( [self.experienceMemory[i] for i in batch_index ])\n",
    "        x = batch[:,0:STATE_NUM].reshape( (self.batch_num,-1)).astype(np.float32)\n",
    "        # print(x)\n",
    "        targets=[]\n",
    "        # targets=np.zeros((x.shape[0],4))\n",
    "        # targets=np.array([self.get_action_value(x[j]) for i in x.shape[0]])\n",
    "        for j in range(x.shape[0]): \n",
    "        #   targets[j]=self.get_action_value(x[j])        \n",
    "            targets.append(np.ndarray.tolist(self.get_action_value(x[j])))\n",
    "        #targets=self.get_action_value(x).data.copy()\n",
    "        targets = np.array(targets)\n",
    "        # print(\"targets=\",targets)\n",
    "        \n",
    "        for i in range(self.batch_num):\n",
    "            #[ seq..., action, reward, seq_new]\n",
    "            a = batch[i,STATE_NUM]\n",
    "            r = batch[i, STATE_NUM+1]\n",
    "            ai=int((a+1)/2) #1 index(0,1)\n",
    "            new_seq= batch[i,(STATE_NUM+2):(STATE_NUM*2+2)]\n",
    "            targets[i,ai]=( r+ self.gamma * np.max(self.get_action_value(new_seq)))\n",
    "        t =targets\n",
    "        #t = Variable(np.array(targets).reshape((self.batch_num,-1)).astype(np.float32))\n",
    "         \n",
    "\n",
    "        # \n",
    "        # self.model.zerograds()\n",
    "        # loss=self.model(x ,t)\n",
    "        # self.loss = loss.data\n",
    "        # loss.backward()\n",
    "        # self.optimizer.update()\n",
    "\n",
    "        # training\n",
    "        for i in range(x.shape[0]):\n",
    "            x1 = x[i]\n",
    "            t2 = t[i]\n",
    "            self.sess.run(self.training, feed_dict={self.x: x1, self.y_: t2})\n",
    "            # for log\n",
    "            self.current_loss = self.sess.run(self.loss, feed_dict={self.x: x1 ,self.y_: t2})\n",
    "\n",
    "\n",
    "class pendulumEnvironment():\n",
    "    '''\n",
    "    model\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.env = wrappers.Monitor(gym.make('CartPole-v0'), './private/tmp/cartpole-experiment-3', force = True)\n",
    "\n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        return self.env.step(action)\n",
    "\n",
    "    def monitor_close(self):\n",
    "        self.env.close()\n",
    "\n",
    "# \n",
    "class simulator:\n",
    "    def __init__(self, environment, agent):\n",
    "        self.agent = agent\n",
    "        self.env = environment\n",
    "        self.num_seq=STATE_NUM\n",
    "        self.reset_seq()\n",
    "        self.learning_rate=1.0\n",
    "        self.highscore=0\n",
    "        self.log=[]\n",
    "\n",
    "    def reset_seq(self):\n",
    "        self.seq=np.zeros(self.num_seq)\n",
    "\n",
    "    def push_seq(self, state):\n",
    "        self.seq[1:self.num_seq]=self.seq[0:self.num_seq-1]\n",
    "        self.seq[0]=state\n",
    "\n",
    "    def run(self, train=True):\n",
    "\n",
    "        self.env.reset()\n",
    "        self.reset_seq()\n",
    "        total_reward=0\n",
    "\n",
    "        for i in range(300):\n",
    "            # state\n",
    "            old_seq = self.seq.copy()\n",
    "\n",
    "            # \n",
    "            action = self.agent.get_action(old_seq,train)\n",
    "\n",
    "            # \n",
    "            observation, reward, done, info =  self.env.step(action)\n",
    "            total_reward +=reward\n",
    "\n",
    "            # state\n",
    "            state = observation[2]\n",
    "            self.push_seq(state)\n",
    "            new_seq = self.seq.copy()\n",
    "\n",
    "            # \n",
    "            self.agent.store_experience(old_seq, action, reward, new_seq,train)\n",
    "            self.agent.experience_local(old_seq, action, reward, new_seq)\n",
    "\n",
    "            if done:\n",
    "                print(\"Episode finished after {} timesteps\".format(i+1))\n",
    "                break\n",
    "\n",
    "        # \n",
    "        self.agent.experience_global(total_reward)\n",
    "\n",
    "        if train:\n",
    "            # \n",
    "            self.agent.update_model(old_seq, action, reward, new_seq)\n",
    "            # self.agent.experience_replay()\n",
    "            self.agent.reduce_epsilon()\n",
    "\n",
    "        return total_reward\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    agent=DQNAgent()\n",
    "    env=pendulumEnvironment()\n",
    "    sim=simulator(env,agent)\n",
    "\n",
    "    best_reward1 = 0\n",
    "    for i in range(1000):\n",
    "        total_reward1 = sim.run(train=True)\n",
    "        if best_reward1 < total_reward1:\n",
    "            best_reward1 = total_reward1\n",
    "\n",
    "        print(str(i) + \" \" + str(total_reward1) + \" \" + str(best_reward1))\n",
    "        env.reset()\n",
    "\n",
    "        if best_reward1 > 195:\n",
    "            break\n",
    "\n",
    "    env.monitor_close()\n",
    "    gym.upload('./private/tmp/cartpole-experiment-3', api_key='sk_GDB9izzTxu1PyxNAdhcw')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
